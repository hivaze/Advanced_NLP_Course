{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "[seminar]text_preprocessing_and_classification.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "11.8333px",
    "width": "160px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "339.717px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3PcL7r1hqySq",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Предобработка текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N-sGLT0vp4jt",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Часть 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wn8EWAjnr18g",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Токенизация"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "btBdBLxbgrNV",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "a7fe3f5c-0700-424e-e917-819007411386",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "eq-QOD9NlO_Q",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "e254cf47-27ef-46b7-c503-2bc58d835f4a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "data = \"All work and no play makes jack a dull boy, all work and no play\"\n",
    "tokens = word_tokenize(data.lower())\n",
    "print(tokens)"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['all', 'work', 'and', 'no', 'play', 'makes', 'jack', 'a', 'dull', 'boy', ',', 'all', 'work', 'and', 'no', 'play']\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "eFDKUzkS6Mci",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "0bbbcfce-22d9-4ea0-8912-877a3ec02baf",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "print(sent_tokenize(\"I was going home when she rung. It was a surprise.\"))"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I was going home when she rung.', 'It was a surprise.']\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "['eejr', ',', 'ejk', '!', 'rjrkrk', ':', 'ekf', ';', 'ekr']"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize('eejr, ejk! rjrkrk: ekf; ekr ')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DQoG7qznyuf5",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "[<img src=\"https://raw.githubusercontent.com/natasha/natasha-logos/master/natasha.svg\">](https://github.com/natasha/natasha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XPeApu2mwYxY",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "[Razdel](https://natasha.github.io/razdel/)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TwJj5Z2fvbeN",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "!pip install -q razdel"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\r\n",
      "\u001B[0m\u001B[33mWARNING: You are using pip version 22.0.4; however, version 22.1.2 is available.\r\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001B[0m\u001B[33m\r\n",
      "\u001B[0m"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uy58Xd_vve-z",
    "outputId": "b5a29b12-0873-4d64-c116-db9da2a2e4f9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "from razdel import tokenize, sentenize\n",
    "text = 'Кружка-термос на 0.5л (50/64 см³, 516;...)'\n",
    "list(tokenize(text))"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "[Substring(0, 13, 'Кружка-термос'),\n Substring(14, 16, 'на'),\n Substring(17, 20, '0.5'),\n Substring(20, 21, 'л'),\n Substring(22, 23, '('),\n Substring(23, 28, '50/64'),\n Substring(29, 32, 'см³'),\n Substring(32, 33, ','),\n Substring(34, 37, '516'),\n Substring(37, 38, ';'),\n Substring(38, 41, '...'),\n Substring(41, 42, ')')]"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VrmhCpNdQo6r",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Регулярные выражения\n",
    "\n",
    "Исчерпывающий пост https://habr.com/ru/post/349860/"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "IccRpcG06Mfd",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "1560c7ef-9dde-45e8-fb5b-0998190cf8ba",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "import re\n",
    "word = 'supercalifragilisticexpialidocious'\n",
    "re.findall('[abc]|up|super', word)"
   ],
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "['super', 'c', 'a', 'a', 'c', 'a', 'c']"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Je8YPHLZPJW7",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "e731e421-3a25-4039-a40f-18d281952745",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "re.findall('\\d{1,3}', 'These are some numbers: 49 and 432312')"
   ],
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "['49', '432', '312']"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fzde8MX1PJXA",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "outputId": "5d638269-ee23-42df-8ed7-50dd63349c45",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "re.sub('[,\\.?!]','','How, to? split. text!')"
   ],
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "'How to split text'"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "GyswV9nuPJXF",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "d4d23159-3e92-4e1d-f7d1-be6ea5dee092",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "re.sub('[^A-z]',' ','I 123 can 45 play 67 football').split()"
   ],
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "['I', 'can', 'play', 'football']"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mz0wIRkRswOQ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Удаление неинформативных слов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "trdPOBM2jEMf",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### N-граммы\n",
    "\n",
    "<img src=\"https://res.cloudinary.com/practicaldev/image/fetch/s--466CQV1q--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://thepracticaldev.s3.amazonaws.com/i/78nf1vryed8h1tz05fim.gif\" height=400>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YYEBfCxLic3R",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "1e6f9ac7-a21f-427a-a421-6d936f2f6b68",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "unigram = list(nltk.ngrams(tokens, 1))\n",
    "bigram = list(nltk.ngrams(tokens, 2))\n",
    "print(unigram[:5])\n",
    "print(bigram[:5])"
   ],
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('all',), ('work',), ('and',), ('no',), ('play',)]\n",
      "[('all', 'work'), ('work', 'and'), ('and', 'no'), ('no', 'play'), ('play', 'makes')]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1AFeZqejmWwN",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "8f9fff61-090e-4e05-adc3-f9052610d5bc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "from nltk import FreqDist\n",
    "print('Популярные униграммы: ', FreqDist(unigram).most_common(5))\n",
    "print('Популярные биграммы: ', FreqDist(bigram).most_common(5))"
   ],
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Популярные униграммы:  [(('all',), 2), (('work',), 2), (('and',), 2), (('no',), 2), (('play',), 2)]\n",
      "Популярные биграммы:  [(('all', 'work'), 2), (('work', 'and'), 2), (('and', 'no'), 2), (('no', 'play'), 2), (('play', 'makes'), 1)]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3W3jJ56hnBFu",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Стоп-слова"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sIBwQ3nBnEfV",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "5f6c8413-a652-4ea6-9b6d-450e099075cb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ],
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "o1nk-TqEslRl",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "e56801a2-c8bf-479a-f1e8-ed312cdb3a9a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "stopWords = set(stopwords.words('english'))\n",
    "print(stopWords)"
   ],
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'y', \"wasn't\", \"hadn't\", 'she', 'what', \"should've\", \"aren't\", 'isn', \"weren't\", \"wouldn't\", \"don't\", 'few', 'does', 'before', 'below', \"it's\", 's', 'ma', 'down', 'to', 'them', 'some', 'needn', 'theirs', 'themselves', 'all', 'than', 'll', 'the', \"shouldn't\", \"hasn't\", 'with', \"you'd\", 'now', 'aren', 'those', \"she's\", 'you', 've', \"isn't\", \"mightn't\", 'weren', 'off', 'again', 'only', 'been', 'its', 'if', 'each', 'any', 'he', 'because', 'o', 'when', \"you're\", 'hadn', 'why', 'they', 'will', 'her', 'between', 'there', 'same', 'so', 'yours', 'myself', \"you've\", 'don', \"needn't\", \"won't\", \"that'll\", 'nor', 'shouldn', 'hasn', \"haven't\", \"doesn't\", 'very', 'just', 'above', 'yourselves', 'am', 'shan', 'own', 'over', 'most', 'which', 'that', 'their', 'itself', 'these', 'then', \"you'll\", 'through', 'other', 'by', 'ourselves', 'under', 'both', 'ain', 'from', 'yourself', 'an', 'couldn', 'or', 're', 'won', 'into', 't', 'can', 'too', 'my', 'had', 'mightn', 'at', 'was', 'after', 'and', 'this', 'but', 'mustn', 'who', 'how', 'whom', 'should', 'm', 'me', 'against', 'wouldn', 'haven', 'himself', 'herself', 'has', 'until', 'doing', \"shan't\", 'for', \"mustn't\", 'were', 'do', 'him', 'are', 'as', 'doesn', 'wasn', 'here', 'more', 'being', 'we', \"couldn't\", 'once', 'where', 'didn', 'your', 'hers', 'd', 'ours', 'having', \"didn't\", 'not', 'on', 'of', 'such', 'our', 'i', 'no', 'in', 'it', 'have', 'further', 'is', 'a', 'during', 'did', 'out', 'be', 'up', 'about', 'his', 'while'}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KFkfJm9ktAVa",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "11e85df4-d2e6-4f9f-ff23-f6cc50fee22b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "print([word for word in tokens if word not in stopWords])"
   ],
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['work', 'play', 'makes', 'jack', 'dull', 'boy', ',', 'work', 'play']\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e5QoqlHiS83f",
    "outputId": "628de9cf-0e10-48ee-e743-448512a7cd13",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "import string\n",
    "print(string.punctuation)"
   ],
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bh-MYv6e-skM",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Стемминг vs Лемматизация\n",
    "* ‘Caring’ -> Лемматизация -> ‘Care’\n",
    "* ‘Caring’ -> Стемминг -> ‘Car’"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aAUKc1oTiQjf",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Стемминг\n",
    "* процесс нахождения основы слова для заданного исходного слова"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "iRVu-TrON4sq",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "from nltk.stem import PorterStemmer, SnowballStemmer\n",
    "words = [\"game\", \"gaming\", \"gamed\", \"games\", \"compacted\"]\n",
    "words_ru = ['корова', 'мальчики', 'мужчины', 'столом', 'убежала']"
   ],
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "L9HTGfsBN9eX",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "e4392b8d-20cb-4a60-9a09-1326d2fdf3f3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "ps = PorterStemmer()\n",
    "list(map(ps.stem, words))"
   ],
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "['game', 'game', 'game', 'game', 'compact']"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "U5qZkB-oODkW",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "b2094c0b-6f4f-431b-801e-107fac105e9f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "ss = SnowballStemmer(language='russian')\n",
    "list(map(ss.stem, words_ru))"
   ],
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "['коров', 'мальчик', 'мужчин', 'стол', 'убежа']"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FbTXbi9FJXr1",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Лематизация\n",
    "* процесс приведения словоформы к лемме — её нормальной (словарной) форме"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QF4nnEz00thb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "raw = \"\"\"DENNIS: Listen, strange women lying in ponds distributing swords\n",
    "is no basis for a system of government.  Supreme executive power derives from\n",
    "a mandate from the masses, not from some farcical aquatic ceremony.\"\"\"\n",
    "\n",
    "raw_ru = \"\"\"Не существует научных доказательств в пользу эффективности НЛП, оно \n",
    "признано псевдонаукой. Систематические обзоры указывают, что НЛП основано на \n",
    "устаревших представлениях об устройстве мозга, несовместимо с современной \n",
    "неврологией и содержит ряд фактических ошибок.\"\"\""
   ],
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mljfOAC4n21I",
    "outputId": "5bf02a63-b1cd-4923-cef6-610c496bad73",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "!pip install -q pymorphy2"
   ],
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\r\n",
      "\u001B[0m\u001B[33mWARNING: You are using pip version 22.0.4; however, version 22.1.2 is available.\r\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001B[0m\u001B[33m\r\n",
      "\u001B[0m"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Zez7jnXl5uJ",
    "outputId": "51782962-44ee-431d-c025-5a70226bf9e7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# 1\n",
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "pymorphy_results = list(map(lambda x: morph.parse(x), raw_ru.split(' ')))\n",
    "print(' '.join([res[0].normal_form for res in pymorphy_results]))"
   ],
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "не существовать научный доказательство в польза эффективность нлп, оно \n",
      "признать псевдонаукой. систематический обзор указывают, что нлп основать на \n",
      "устаревший представление о устройство мозга, несовместимый с современный \n",
      "неврология и содержать ряд фактический ошибок.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-11 04:18:56.031980: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\r\n",
      "2022-06-11 04:18:56.032009: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\n",
      "Collecting en-core-web-sm==3.3.0\r\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.3.0/en_core_web_sm-3.3.0-py3-none-any.whl (12.8 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m12.8/12.8 MB\u001B[0m \u001B[31m13.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: spacy<3.4.0,>=3.3.0.dev0 in /usr/local/lib/python3.8/dist-packages (from en-core-web-sm==3.3.0) (3.3.0)\r\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.7.7)\r\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.7)\r\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.8.2)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.27.1)\r\n",
      "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.6.1)\r\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.3.0)\r\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.4.3)\r\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.6)\r\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.7)\r\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.4.1)\r\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.8/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.9)\r\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.6)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (20.9)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (4.64.0)\r\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /usr/local/lib/python3.8/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (8.0.16)\r\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.9.1)\r\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.21.6)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.1.1)\r\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (62.1.0)\r\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.2)\r\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.8)\r\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from pathy>=0.3.5->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (5.2.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (4.2.0)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.26.9)\r\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.12)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2021.10.8)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.3)\r\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (8.1.2)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.1)\r\n",
      "Installing collected packages: en-core-web-sm\r\n",
      "Successfully installed en-core-web-sm-3.3.0\r\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\r\n",
      "\u001B[0m\u001B[33mWARNING: You are using pip version 22.0.4; however, version 22.1.2 is available.\r\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001B[0m\u001B[33m\r\n",
      "\u001B[0m\u001B[38;5;2m✔ Download and installation successful\u001B[0m\r\n",
      "You can now load the package via spacy.load('en_core_web_sm')\r\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy download en_core_web_sm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import spacy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "w7MDqIvWib4O",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "93dee74a-4769-4473-a6bb-e3e0b71bad2e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# 2\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "spacy_results = nlp(raw)\n",
    "print(' '.join([token.lemma_ for token in spacy_results]))"
   ],
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dennis : listen , strange woman lie in pond distribute sword \n",
      " be no basis for a system of government .   Supreme executive power derive from \n",
      " a mandate from the masse , not from some farcical aquatic ceremony .\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOUN PUNCT VERB PUNCT ADJ NOUN VERB ADP NOUN VERB NOUN SPACE AUX DET NOUN ADP DET NOUN ADP NOUN PUNCT SPACE PROPN ADJ NOUN VERB ADP SPACE DET NOUN ADP DET NOUN PUNCT PART ADP DET ADJ ADJ NOUN PUNCT\n"
     ]
    }
   ],
   "source": [
    "print(' '.join([token.pos_ for token in spacy_results]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LVC5gjCRk5bD",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "[Сравнение PyMorphy2 и PyMystem3](https://habr.com/ru/post/503420/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yim_NVYA6MeS",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Part-of-Speech"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2t_MamYKqbSk",
    "outputId": "17c3a9fc-4fc2-4d0f-9353-a76e653cf6f0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# 1\n",
    "[(res[0].normal_form, res[0].tag) for res in pymorphy_results[:9]]"
   ],
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "[('не', OpencorporaTag('PRCL')),\n ('существовать', OpencorporaTag('VERB,impf,intr sing,3per,pres,indc')),\n ('научный', OpencorporaTag('ADJF,Qual plur,gent')),\n ('доказательство', OpencorporaTag('NOUN,inan,neut plur,gent')),\n ('в', OpencorporaTag('PREP')),\n ('польза', OpencorporaTag('NOUN,inan,femn sing,accs')),\n ('эффективность', OpencorporaTag('NOUN,inan,femn sing,gent')),\n ('нлп,', OpencorporaTag('UNKN')),\n ('оно', OpencorporaTag('NPRO,neut,3per,Anph sing,nomn'))]"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Doa85yw6JWea",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "794ec981-0378-4020-e316-f1e2045d8949",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# 2\n",
    "[(token.lemma_, token.pos_) for token in spacy_results[:7]]"
   ],
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "[('dennis', 'NOUN'),\n (':', 'PUNCT'),\n ('listen', 'VERB'),\n (',', 'PUNCT'),\n ('strange', 'ADJ'),\n ('woman', 'NOUN'),\n ('lie', 'VERB')]"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EVGJLVjLtFDp",
    "outputId": "c01be447-80df-4477-c875-28889e7b7e36",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "!pip install -q rnnmorph"
   ],
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\r\n",
      "\u001B[0m\u001B[33mWARNING: You are using pip version 22.0.4; however, version 22.1.2 is available.\r\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001B[0m\u001B[33m\r\n",
      "\u001B[0m"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Ms2yeEFqrtZ",
    "outputId": "dd9131e0-82bd-46a7-e54e-1bed989ff9fb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# 3\n",
    "from rnnmorph.predictor import RNNMorphPredictor\n",
    "predictor = RNNMorphPredictor(language=\"ru\")\n",
    "rnnmorph_result = predictor.predict(raw_ru.split(' '))\n",
    "[(token.normal_form, token.pos, token.tag) for token in rnnmorph_result[:7]]"
   ],
   "execution_count": 38,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-11 04:33:52.698574: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-06-11 04:33:52.698602: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-06-11 04:33:52.698620: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (master-node): /proc/driver/nvidia/version does not exist\n",
      "2022-06-11 04:33:52.698788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 748ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "[('не', 'PART', '_'),\n ('существовать',\n  'VERB',\n  'Mood=Ind|Number=Sing|Person=3|Tense=Notpast|VerbForm=Fin|Voice=Act'),\n ('научный', 'ADJ', 'Case=Gen|Degree=Pos|Number=Plur'),\n ('доказательство', 'NOUN', 'Case=Gen|Gender=Neut|Number=Plur'),\n ('в', 'ADP', '_'),\n ('польза', 'NOUN', 'Case=Acc|Gender=Fem|Number=Sing'),\n ('эффективность', 'NOUN', 'Case=Gen|Gender=Fem|Number=Sing')]"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3_Slt2R76Mgk",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Named entities recognition"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zvB43ZHT6MhR",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "3d490cfc-0b7f-4cb1-f655-7e9ca16f6a2d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "doc = nlp('Apple is looking at buying U.K. startup for $1 billion')\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ],
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple 0 5 ORG\n",
      "U.K. 27 31 GPE\n",
      "$1 billion 44 54 MONEY\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z0-_oFwwqAwN",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Часть 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HIwDfmrYOMfi",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Задача классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L6DaLniC6MhY",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 20 newsgroups\n",
    "Датасет с 18000 новостей, сгруппированных по 20 темам."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9uS7IJNW6Mhb",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "ebc2f876-92c7-4032-a422-d51b2e3c2c4a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')"
   ],
   "execution_count": 40,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MMbagpJE6Mhh",
    "scrolled": false,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "152aa470-abef-47d0-deb1-2bcef6280e07",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "newsgroups_train.target_names"
   ],
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "['alt.atheism',\n 'comp.graphics',\n 'comp.os.ms-windows.misc',\n 'comp.sys.ibm.pc.hardware',\n 'comp.sys.mac.hardware',\n 'comp.windows.x',\n 'misc.forsale',\n 'rec.autos',\n 'rec.motorcycles',\n 'rec.sport.baseball',\n 'rec.sport.hockey',\n 'sci.crypt',\n 'sci.electronics',\n 'sci.med',\n 'sci.space',\n 'soc.religion.christian',\n 'talk.politics.guns',\n 'talk.politics.mideast',\n 'talk.politics.misc',\n 'talk.religion.misc']"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7QReW1K46Mhn",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "d243da37-1e2a-4a19-e22b-960f369915c7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "newsgroups_train.filenames.shape"
   ],
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "(11314,)"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WZtRIQmNQ4H0",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Рассмотрим подвыборку"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "OhwuCp5B6Mhz",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "53f9bb20-9762-49b3-f2f2-0327bde7d576",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "categories = ['alt.atheism', 'talk.religion.misc',\n",
    "              'comp.graphics', 'sci.space']\n",
    "newsgroups_train = fetch_20newsgroups(subset='train',\n",
    "                                      categories=categories)\n",
    "newsgroups_train.filenames.shape"
   ],
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "(2034,)"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MOREsv336MiA",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "f91d5c50-4e47-4ba9-cbbe-37acf3df847a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "print(newsgroups_train.data[2])"
   ],
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: Mark.Perew@p201.f208.n103.z1.fidonet.org\n",
      "Subject: Re: Comet in Temporary Orbit Around Jupiter?\n",
      "X-Sender: newtout 0.08 Feb 23 1993\n",
      "Lines: 15\n",
      "\n",
      "In a message of <Apr 19 04:55>, jgarland@kean.ucs.mun.ca writes:\n",
      "\n",
      " >In article <1993Apr19.020359.26996@sq.sq.com>, msb@sq.sq.com (Mark Brader) \n",
      " >writes:\n",
      "\n",
      "MB>                                                             So the\n",
      "MB> 1970 figure seems unlikely to actually be anything but a perijove.\n",
      "\n",
      "JG>Sorry, _perijoves_...I'm not used to talking this language.\n",
      "\n",
      "Couldn't we just say periapsis or apoapsis?\n",
      "\n",
      " \n",
      "\n",
      "--- msged 2.07\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SBnDG-TN6MiF",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "33bc189f-0161-4287-bf48-e78fcdadd683",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "newsgroups_train.target[:10]"
   ],
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "array([1, 3, 2, 0, 2, 0, 2, 1, 2, 1])"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2XlZYpodRYDI",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### TF-IDF(напоминание)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ohUk2n3jRbNp",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "$n_{\\mathbb{d}\\mathbb{w}}$ - число вхождений слова $\\mathbb{w}$ в документ $\\mathbb{d}$;<br>\n",
    "$N_{\\mathbb{w}}$ - число документов, содержащих $\\mathbb{w}$;<br>\n",
    "$N$ - число документов; <br><br>\n",
    "\n",
    "$p(\\mathbb{w}, \\mathbb{d}) = N_{\\mathbb{w}} / N$ - вероятность наличия слова $\\mathbb{w}$ в любом документе $\\mathbb{d}$\n",
    "<br>\n",
    "$P(\\mathbb{w}, \\mathbb{d}, n_{\\mathbb{d}\\mathbb{w}}) = (N_{\\mathbb{w}} / N)^{n_{\\mathbb{d}\\mathbb{w}}}$ - вероятность встретить $n_{\\mathbb{d}\\mathbb{w}}$ раз слово $\\mathbb{w}$ в документе $\\mathbb{d}$<br><br>\n",
    "\n",
    "$-\\log{P(\\mathbb{w}, \\mathbb{d}, n_{\\mathbb{d}\\mathbb{w}})} = n_{\\mathbb{d}\\mathbb{w}} \\cdot \\log{(N / N_{\\mathbb{w}})} = TF(\\mathbb{w}, \\mathbb{d}) \\cdot IDF(\\mathbb{w})$<br><br>\n",
    "\n",
    "$TF(\\mathbb{w}, \\mathbb{d}) = n_{\\mathbb{d}\\mathbb{w}}$ - term frequency;<br>\n",
    "$IDF(\\mathbb{w}) = \\log{(N /N_{\\mathbb{w}})}$ - inverted document frequency;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kQvcMiFH6MiM",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Давайте векторизуем эти тексты с помощью TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "98LLAoZO6MiU",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ],
   "execution_count": 45,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "baXLU0lj6MiY",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Некоторые параметры: \n",
    "* input : string {‘filename’, ‘file’, ‘content’}\n",
    "*  lowercase : boolean, default True\n",
    "*  preprocessor : callable or None (default)\n",
    "*  tokenizer : callable or None (default)\n",
    "*  stop_words : string {‘english’}, list, or None (default)\n",
    "*  ngram_range : tuple (min_n, max_n)\n",
    "*  max_df : float in range [0.0, 1.0] or int, default=1.0\n",
    "*  min_df : float in range [0.0, 1.0] or int, default=1\n",
    "*  max_features : int or None, default=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O-m81BJxZFwJ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Перебор параметров"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_f7padHL6MiZ",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "a60445fa-ad78-4efb-ad13-51a8a59f5650",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# lowercase\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
    "vectors.shape"
   ],
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "(2034, 34118)"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Nf2s4HCY6Mie",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "159178a7-2cb6-438f-93fd-2532ec410368",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "vectorizer = TfidfVectorizer(lowercase=False)\n",
    "vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
    "vectors.shape"
   ],
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "(2034, 42307)"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2hwlTWapZR8M",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "e2ced468-e4d8-497c-8f27-4262fba6eea1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "vectorizer.get_feature_names()[:10]"
   ],
   "execution_count": 48,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": "['00',\n '000',\n '0000',\n '00000',\n '000000',\n '000005102000',\n '000021',\n '000062David42',\n '0000VEC',\n '0001']"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "AYfpk0ds6Mij",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "a605ac46-771c-44cd-c5c9-0774625740d8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# min_df, max_df\n",
    "vectorizer = TfidfVectorizer(min_df=0.8)\n",
    "vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
    "vectors.shape"
   ],
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "(2034, 9)"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Ookt99atZ8sS",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "48acde37-ce1c-46e4-e131-bf3d99a36d4d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "vectorizer.get_feature_names()"
   ],
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "['and', 'from', 'in', 'lines', 'of', 'organization', 'subject', 'the', 'to']"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2e_h6c0X6Mim",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "1164d096-e211-478d-cb27-cc782b71690e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "vectorizer = TfidfVectorizer(min_df=0.01, max_df=0.8)\n",
    "vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
    "vectors.shape"
   ],
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "(2034, 2391)"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XUhOyx4NihL0",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "c5bdb88a-8a3b-4654-b0b4-9a8a5c79e132",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# ngram_range\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 3), min_df=0.03, max_df=0.9)\n",
    "vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
    "vectors.shape"
   ],
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "(2034, 1236)"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7074cdSF6MjC",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "outputId": "378752c9-3ae1-436f-d3c5-568363006d90",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# стоп-слова, preproc\n",
    "from nltk.corpus import stopwords\n",
    "stopWords = set(stopwords.words('english'))\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "wnl = nltk.WordNetLemmatizer()\n",
    "\n",
    "def preproc_nltk(text):\n",
    "    #text = re.sub(f'[{string.punctuation}]', ' ', text)\n",
    "    return ' '.join([wnl.lemmatize(word) for word in word_tokenize(text.lower()) if word not in stopWords])\n",
    "\n",
    "st = \"Oh, I think I ve landed Where there are miracles at work,  For the thirst and for the hunger Come the conference of birds\"\n",
    "preproc_nltk(st)"
   ],
   "execution_count": 55,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/omw-1.4.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": "'oh , think landed miracle work , thirst hunger come conference bird'"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "LIW3hCSy6MjX",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "338c71af-0740-4c8f-c058-684dd087ad97",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "%%time\n",
    "vectorizer = TfidfVectorizer(preprocessor=preproc_nltk)\n",
    "vectors = vectorizer.fit_transform(newsgroups_train.data)"
   ],
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.78 s, sys: 0 ns, total: 4.78 s\n",
      "Wall time: 4.78 s\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "lUmyAzJEB1SU",
    "outputId": "f7b9009d-14f0-4436-e2e5-b7082f7aa6b5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# preproc_spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "texts = newsgroups_train.data.copy()\n",
    "\n",
    "def preproc_spacy(text):\n",
    "    spacy_results = nlp(text)\n",
    "    return ' '.join([token.lemma_ for token in spacy_results if token.lemma_ not in stopWords])\n",
    "preproc_spacy(st)"
   ],
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "'oh , I think I land miracle work ,   thirst hunger come conference bird'"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0C5Ent0nG5zj",
    "outputId": "1af1abe9-bc09-480f-ced0-5caf77a7e0d7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "%%time\n",
    "new_texts = []\n",
    "for doc in nlp.pipe(texts, batch_size=32, n_process=3, disable=[\"parser\", \"ner\"]):\n",
    "    new_texts.append(' '.join([tok.lemma_ for tok in doc if tok.lemma not in stopWords]))\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(new_texts)"
   ],
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.58 s, sys: 179 ms, total: 5.76 s\n",
      "Wall time: 20.6 s\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0lXAPHZA6Mj0",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Итоговая модель"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uZYcRkQ86Mj1",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "72392257-a3e9-405a-9238-169e7c0d115c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1, 3), max_df=0.5, max_features=1000)\n",
    "vectors = vectorizer.fit_transform(new_texts)\n",
    "vectorizer.get_feature_names()[::100]"
   ],
   "execution_count": 59,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": "['000',\n 'attempt',\n 'choice',\n 'else',\n 'how to',\n 'livesey',\n 'of technology',\n 'report',\n 'tell',\n 'understand']"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TQHTlj3q6Mj6",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Можем посмотреть на косинусную меру между векторами"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VA8Fn5I46Mi0",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "632e1709-57eb-416c-f579-eaad32195408",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "vector = vectors.todense()[0]\n",
    "vector.shape, (vector != 0).sum()"
   ],
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "((1, 1000), 52)"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VsVQhR9y6Mj8",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "378d430b-f6d2-4f76-e2d9-bda51d8479de",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "type(vectors)"
   ],
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "scipy.sparse._csr.csr_matrix"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "89.9188790560472"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(list(map(lambda x: (x != 0).sum(), vectors.todense())))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "tS2G0ZZC6MkN",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "7dc5ec75-cf8e-4c15-a759-631dc63c6c57",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "dense_vectors = vectors.todense()\n",
    "dense_vectors.shape"
   ],
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "(2034, 1000)"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "LGgb5aP76MkU",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "def cosine_sim(v1, v2):\n",
    "    # v1, v2 (1 x dim)\n",
    "    return np.array(v1 @ v2.T / norm(v1) / norm(v2))[0][0]"
   ],
   "execution_count": 73,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "l_FrKM6k6MkY",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "462e7b13-1aa4-4506-e605-49feaf5ab150",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "cosine_sim(dense_vectors[0], dense_vectors[0])"
   ],
   "execution_count": 74,
   "outputs": [
    {
     "data": {
      "text/plain": "1.0"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "data": {
      "text/plain": "0.031615400434166746"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim(dense_vectors[0], dense_vectors[-1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "L1XF-isH6Mkh",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "cosines = []\n",
    "for i in range(10):\n",
    "    cosines.append(cosine_sim(dense_vectors[0], dense_vectors[i]))"
   ],
   "execution_count": 75,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ODwgYEbe6Mkl",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "b6959653-9dea-438a-9590-9c2afedceab4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# [1, 3, 2, 0, 2, 0, 2, 1, 2, 1]\n",
    "cosines"
   ],
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "[1.0,\n 0.04198925923903864,\n 0.0058283978209930296,\n 0.08031436700254609,\n 0.07087677381802292,\n 0.05861858660776199,\n 0.033532109993680136,\n 0.2283363266924496,\n 0.03206849266448253,\n 0.05747357727935911]"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SRZyJP3c6Mkq",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Обучим любую известную модель на полученных признаках"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4RDfl72A6Mks",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "881d3b15-aa8b-479b-ce66-a06e91e47824",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test= train_test_split(dense_vectors, newsgroups_train.target, test_size=0.2, random_state=0)\n",
    "y_train.shape, y_test.shape"
   ],
   "execution_count": 84,
   "outputs": [
    {
     "data": {
      "text/plain": "((1627,), (407,))"
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vjfwduNp6Mlo",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "8d86a9ea-2a38-487a-8147-1b2d6f5c7ab6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "%%time\n",
    "svc = svm.SVC()\n",
    "svc.fit(X_train, y_train)"
   ],
   "execution_count": 85,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 961 ms, sys: 6.21 ms, total: 967 ms\n",
      "Wall time: 961 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": "SVC()"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "N6Evwipx6Mlv",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "943c6663-6329-4ad4-d040-1f54b4ea80f7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "accuracy_score(y_test, svc.predict(X_test))"
   ],
   "execution_count": 86,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.9238329238329238"
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6EBZRbXT6Mly",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "1b992f83-1c25-4e3d-f536-b284d660e1e4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "sgd = SGDClassifier()\n",
    "sgd.fit(X_train, y_train)\n",
    "accuracy_score(y_test, sgd.predict(X_test))"
   ],
   "execution_count": 87,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.9115479115479116"
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i5OAwBJ0LuPb",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SKLGAYPvPJcJ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "import gensim.downloader as api\n",
    "embeddings_pretrained = api.load('glove-twitter-25')"
   ],
   "execution_count": 90,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===========---------------------------------------] 22.4% 23.4/104.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===================================---------------] 70.8% 74.2/104.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "data": {
      "text/plain": "<gensim.models.keyedvectors.KeyedVectors at 0x7f9385c39d00>"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_pretrained"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fmH3vc7FSCuP",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "proc_words = [preproc_nltk(text).split() for text in newsgroups_train.data]\n",
    "embeddings_trained = Word2Vec(proc_words, # data for model to train on\n",
    "                 size=100,                 # embedding vector size\n",
    "                 min_count=3,             # consider words that occured at least 5 times\n",
    "                 window=3).wv"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0Lq20widPJcO",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "def vectorize_sum(comment, embeddings):\n",
    "    \"\"\"\n",
    "    implement a function that converts preprocessed comment to a sum of token vectors\n",
    "    \"\"\"\n",
    "    embedding_dim = embeddings.vectors.shape[1]\n",
    "    features = np.zeros([embedding_dim], dtype='float32')\n",
    "\n",
    "    for word in preproc_nltk(comment).split():\n",
    "        if word in embeddings:\n",
    "            features += embeddings[f'{word}']\n",
    "    \n",
    "    return features"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h1KaMKBHsSHd",
    "outputId": "65336ef9-6d63-4c40-881d-d22ca4b8b2c5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "len(embeddings_trained.index2word)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "13651"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 102
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "krjpVRsLPJcf",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "0f24b897-f3c5-4ee7-84fe-1ca5a2abeafe",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "X_wv = np.stack([vectorize_sum(text, embeddings_pretrained) for text in newsgroups_train.data])\n",
    "X_train_wv, X_test_wv, y_train, y_test = train_test_split(X_wv, newsgroups_train.target, test_size=0.2, random_state=0)\n",
    "X_train_wv.shape, X_test_wv.shape"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((1627, 25), (407, 25))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 95
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "oWhQ007PPJcn",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "ba51dbd6-e7ef-4ed5-eac0-948d32f76a5c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "clf = LogisticRegression(max_iter=5000)\n",
    "wv_model = clf.fit(X_train_wv, y_train)\n",
    "accuracy_score(y_test, wv_model.predict(X_test_wv))"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7100737100737101"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 96
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oT_Rr4nOUUu8",
    "outputId": "08a28d12-283e-4eab-d80c-6208cc6ceadd",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "X_wv = np.stack([vectorize_sum(text, embeddings_trained) for text in newsgroups_train.data])\n",
    "X_train_wv, X_test_wv, y_train, y_test = train_test_split(X_wv, newsgroups_train.target, test_size=0.2, random_state=0)\n",
    "X_train_wv.shape, X_test_wv.shape"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((1627, 100), (407, 100))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 104
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uVMeZBLbVMjO",
    "outputId": "653442de-cfa8-4170-bfa6-1f87e00a6e29",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "clf = LogisticRegression(max_iter=10000)\n",
    "wv_model = clf.fit(X_train_wv, y_train)\n",
    "accuracy_score(y_test, wv_model.predict(X_test_wv))"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8402948402948403"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 109
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "F_K8NLmDVds1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [],
   "execution_count": null,
   "outputs": []
  }
 ]
}